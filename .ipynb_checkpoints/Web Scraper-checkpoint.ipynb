{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports needed to make the project run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from datetime import datetime, timedelta, date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Time Setting, and Keywords from Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "time = \"\"\n",
    "keywords = \"\"\n",
    "\n",
    "with open(\"Time Setting and Keywords - Export.tsv\", \"r\") as file:\n",
    "    time += file.readline().strip()\n",
    "    keywords = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Google News URL used to Scrape News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "url = f\"https://www.google.com/search?q=&source=lnms&tbm=nws\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-Scraper used to get the Link for the Time-Frame User Selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pre_Scraper(url,keyword,time):\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    url = url[:32] + keyword + url[32:]\n",
    "\n",
    "    driver.get(url)\n",
    "    sleep(0.5)\n",
    "    page = driver.find_element(By.ID,\"hdtb-tls\").click()\n",
    "    sleep(0.5)\n",
    "    page = driver.find_element(By.CLASS_NAME,\"KTBKoe\").click()\n",
    "\n",
    "    if time == \"Past hour\":\n",
    "        page = driver.find_element(By.LINK_TEXT,\"Past hour\").click()\n",
    "        url = driver.current_url\n",
    "    elif time == \"Past 24 hours\":\n",
    "        page = driver.find_element(By.LINK_TEXT,\"Past 24 hours\").click()\n",
    "        url = driver.current_url\n",
    "    elif time == \"Past week\":\n",
    "        page = driver.find_element(By.LINK_TEXT,\"Past week\").click()\n",
    "        url = driver.current_url\n",
    "    elif time == \"Past month\":\n",
    "        page = driver.find_element(By.LINK_TEXT,\"Past month\").click()\n",
    "        url = driver.current_url\n",
    "    elif time == \"Past year\":\n",
    "        page = driver.find_element(By.LINK_TEXT,\"Past year\").click()\n",
    "        url = driver.current_url\n",
    "\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function used to go to the Next page of Google News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def next_Pages(url,pages):\n",
    "\n",
    "    newsArticles = []\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.get(url)\n",
    "    sleep(1)\n",
    "\n",
    "    for i in range(pages):\n",
    "        try:\n",
    "            newsArticles.append(news_Scraper(driver.page_source))\n",
    "            next_Icon = WebDriverWait(driver,0.5).until(\n",
    "                EC.presence_of_element_located((By.ID,\"pnnext\"))\n",
    "            )\n",
    "            next_Icon.click()\n",
    "        except:\n",
    "            driver.close()\n",
    "            return newsArticles\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Function used for Scrapping the News for a certain Keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def news_Scraper(pageSoruce):\n",
    "\n",
    "    pageArticles = []\n",
    "\n",
    "    page = BeautifulSoup(pageSoruce,'lxml')\n",
    "\n",
    "    articles = page.find_all('div',class_='xuvV6b BGxR7d')\n",
    "\n",
    "    for article in articles:\n",
    "        Title = article.find('div',class_='mCBkyc y355M ynAwRc MBeuO nDgy9d').get_text().replace(\"\\n\",\"\").replace(\"...\",\"\")\n",
    "        Descirption = article.find('div', class_='GI74Re nDgy9d').get_text().replace(\"\\n\",\"\").replace(\"...\",\"\")\n",
    "        Time = article.find('div', class_='OSrXXb ZE0LJd').get_text()\n",
    "        Link = article.find('a',href=True)['href']\n",
    "        pageArticles.append((Title,Descirption,Time,Link))\n",
    "\n",
    "    return pageArticles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function used to give the CSV file a detailed name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def csv_File_Name(keyword,time):\n",
    "\n",
    "    date_today = datetime.today()\n",
    "\n",
    "    if time == \"Past hour\":\n",
    "        file_name = f\"{keyword} articles from {(date_today - timedelta(hours=1)).strftime('%Y-%m-%d %H.%M')} to {date_today.strftime('%Y-%m-%d %H.%M')}.csv\"\n",
    "    elif time == \"Past 24 hours\":\n",
    "        file_name = f\"{keyword} articles from {(date_today - timedelta(days=1)).strftime('%Y-%m-%d %H.%M')} to {date_today.strftime('%Y-%m-%d %H.%M')}.csv\"\n",
    "    elif time == \"Past week\":\n",
    "        file_name = f\"{keyword} articles from {(date_today - timedelta(days=7)).strftime('%Y-%m-%d %H.%M')} to {date_today.strftime('%Y-%m-%d %H.%M')}.csv\"\n",
    "    elif time == \"Past month\":\n",
    "        file_name = f\"{keyword} articles from {(date_today - relativedelta(months=1)).strftime('%Y-%m-%d %H.%M')} to {date_today.strftime('%Y-%m-%d %H.%M')}.csv\"\n",
    "    elif time == \"Past year\":\n",
    "        file_name = f\"{keyword} articles from {(date_today - relativedelta(years=1)).strftime('%Y-%m-%d %H.%M')} to {date_today.strftime('%Y-%m-%d %H.%M')}.csv\"\n",
    "    else:\n",
    "        file_name = f\"{keyword} articles from {date_today.strftime('%Y-%m-%d %H.%M')} to no specified date and time.csv\"\n",
    "\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flattens the 3d Array into a list of tuples for each News Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def newsArticleFlatter(newsArticles):\n",
    "    newsArticles = [tup for group in newsArticles for tup in group]\n",
    "    return newsArticles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function used to write the News Articles into the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def csv_Writer(news_articles, keyword,time):\n",
    "\n",
    "    file_name = csv_File_Name(keyword,time)\n",
    "    headers = ['Title', 'Description', 'Publication Date (Relative To When Script Was Run)', 'Link']\n",
    "\n",
    "    with open(file_name,'w',newline=\"\",encoding='utf-8-sig') as file:\n",
    "        rowWrite = csv.writer(file)\n",
    "        rowWrite.writerow(headers)\n",
    "        for news in news_articles:\n",
    "            rowWrite.writerow(news)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used to create CSV Files for each Keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for keyword in keywords:\n",
    "    basePageUrl = pre_Scraper(url,keyword,time)\n",
    "    newsArticles = next_Pages(basePageUrl,10)\n",
    "    flatNewsArticles = newsArticleFlatter(newsArticles)\n",
    "    csv_Writer(flatNewsArticles,keyword,time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
